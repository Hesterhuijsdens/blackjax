
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>MNIST Digit Recognition With a 3-Layer Perceptron &#8212; Blackjax</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Change of Variable in HMC" href="change_of_variable_hmc.html" />
    <link rel="prev" title="Bayesian Regression With Latent Gaussian Sampler" href="GP_Marginal.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/blackjax.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Blackjax</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  HOW TO
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../howto_use_ppl.html">
   Use the model I built with X?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_aesara.html">
     Use with Aesara models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_numpyro.html">
     Use with Numpyro models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_oryx.html">
     Use with Oryx models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_tfp.html">
     Use with TFP models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_sample_multiple_chains.html">
   Sample with multiple chains?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_custom_gradients.html">
   Use custom gradients?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_other_frameworks.html">
   Use non-JAX log-prob functions?
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Blackjax by example
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../examples.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Introduction.html">
     A Quick Introduction to Blackjax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegression.html">
     Bayesian Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegressionWithLatentGaussianSampler.html">
     Bayesian Logistic Regression With Latent Gaussian Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="TemperedSMC.html">
     Use Tempered SMC to Improve Exploration of MCMC Methods.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalBNN.html">
     Hierarchical Bayesian Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="PeriodicOrbitalMCMC.html">
     Periodic Orbital MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GP_EllipticalSliceSampler.html">
     Gaussian Regression with the Elliptical Slice Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GP_Marginal.html">
     Bayesian Regression With Latent Gaussian Sampler
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     MNIST Digit Recognition With a 3-Layer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="change_of_variable_hmc.html">
     Change of Variable in HMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Pathfinder.html">
     Pathfinder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RegimeSwitchingModel.html">
     Regime switching Hidden Markov model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SparseLogisticRegression.html">
     Sparse logistic regression
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mcmc.html">
   MCMC sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sgmcmc.html">
   Stochastic gradient MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../smc.html">
   Sequential Monte Carlo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vi.html">
   Variational Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../adaptation.html">
   Adaptation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../diagnostics.html">
   Diagnostics
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/blackjax-devs/blackjax"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   Data Preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-3-layer-perceptron">
   Model: 3-layer Perceptron
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-from-the-posterior-distribution-of-the-perceptron-s-weights">
   Sample From the Posterior Distribution of the Perceptron’s Weights
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sampling-with-sghmc">
     Sampling with SGHMC
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>MNIST Digit Recognition With a 3-Layer Perceptron</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   Data Preparation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-3-layer-perceptron">
   Model: 3-layer Perceptron
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-from-the-posterior-distribution-of-the-perceptron-s-weights">
   Sample From the Posterior Distribution of the Perceptron’s Weights
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sampling-with-sghmc">
     Sampling with SGHMC
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="mnist-digit-recognition-with-a-3-layer-perceptron">
<h1>MNIST Digit Recognition With a 3-Layer Perceptron<a class="headerlink" href="#mnist-digit-recognition-with-a-3-layer-perceptron" title="Permalink to this headline">#</a></h1>
<p>This example is inspired form <a class="reference external" href="https://github.com/jeremiecoullon/SGMCMCJax/blob/master/docs/nbs/BNN.ipynb">this notebook</a> in the SGMCMCJax repository. We try to use a 3-layer neural network to recognise the digits in the MNIST dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">flax.linen</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">distrax</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
</pre></div>
</div>
</div>
</div>
<section id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">#</a></h2>
<p>We download the MNIST data using <code class="docutils literal notranslate"><span class="pre">tensorflow-datasets</span></code>:</p>
<div class="cell tag_remove-stdout tag_remove-stderr docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>

<span class="n">mnist_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">mnist_data</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">mnist_data</span><span class="p">)</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span> <span class="o">=</span> <span class="n">mnist_data</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span> <span class="n">mnist_data</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Now we need to apply several transformations to the dataset before splitting it into a test and a test set:</p>
<ul class="simple">
<li><p>The images come into 28x28 pixels matrices; we reshape them into a vector;</p></li>
<li><p>The images are arrays of RGB codes between 0 and 255. We normalize them by the maximum value to get a range between 0 and 1;</p></li>
<li><p>We hot-encode category numbers.</p></li>
</ul>
<div class="cell tag_remove-stdout tag_remove-stderr docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="s2">&quot;Create a one-hot encoding of x of size k.&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">num_categories</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_categories</span><span class="p">)</span>

    <span class="n">num_examples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_pixels</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">num_pixels</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="mf">255.0</span>

    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">num_examples</span>


<span class="k">def</span> <span class="nf">batch_data</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return an iterator over batches of data.&quot;&quot;&quot;</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">data_size</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span>
        <span class="p">)</span>
        <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">elem</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">minibatch</span>


<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">N_train</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">N_test</span> <span class="o">=</span> <span class="n">prepare_data</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</section>
<section id="model-3-layer-perceptron">
<h2>Model: 3-layer Perceptron<a class="headerlink" href="#model-3-layer-perceptron" title="Permalink to this headline">#</a></h2>
<p>We will use a very simple (bayesian) neural network in this example: A MLP with gaussian priors on the weights. We first need a function that computes the model’s logposterior density given the data and the current values of the parameters. If we note <span class="math notranslate nohighlight">\(X\)</span> the array that represents an image and <span class="math notranslate nohighlight">\(y\)</span> the array such that <span class="math notranslate nohighlight">\(y_i = 0\)</span>  if the image is in category <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(y_i=1\)</span> otherwise, the model can be written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
  \boldsymbol{p} &amp;= \operatorname{NN}(X)\\
  \boldsymbol{y} &amp;\sim \operatorname{Categorical}(\boldsymbol{p})
\end{align*}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">100</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">10</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">NN</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">logprior_fn</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the value of the log-prior density function.&quot;&quot;&quot;</span>
    <span class="n">leaves</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_util</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">flat_params</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">leaves</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">distrax</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">flat_params</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">loglikelihood_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Categorical log-likelihood&quot;&quot;&quot;</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>


<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the accuracy of the model.</span>

<span class="sd">    To make predictions we take the number that corresponds to the highest probability value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">target_class</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_class</span> <span class="o">==</span> <span class="n">target_class</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="sample-from-the-posterior-distribution-of-the-perceptron-s-weights">
<h2>Sample From the Posterior Distribution of the Perceptron’s Weights<a class="headerlink" href="#sample-from-the-posterior-distribution-of-the-perceptron-s-weights" title="Permalink to this headline">#</a></h2>
<p>Now we need to get initial values for the parameters, and we simply sample from their prior distribution:</p>
<p>We now sample from the model’s posteriors using SGLD. We discard the first 1000 samples until the sampler has reached the typical set, and then take 2000 samples. We record the model’s accuracy with the current values every 100 steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">progress_bar</span>

<span class="kn">import</span> <span class="nn">blackjax</span>
<span class="kn">import</span> <span class="nn">blackjax.sgmcmc.gradients</span> <span class="k">as</span> <span class="nn">gradients</span>


<span class="n">data_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">5e-5</span>

<span class="n">num_warmup</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_size</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="mi">20</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Batch the data</span>
<span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">batches</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">(</span><span class="n">rng_key</span><span class="p">,</span> <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data_size</span><span class="p">)</span>

<span class="c1"># Set the initial state</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">init</span><span class="p">)(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Build the SGLD kernel with a constant learning rate</span>
<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="n">logprior_fn</span><span class="p">,</span> <span class="n">loglikelihood_fn</span><span class="p">,</span> <span class="n">data_size</span><span class="p">)</span>
<span class="n">sgld</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">sgld</span><span class="p">(</span><span class="n">grad_fn</span><span class="p">)</span>

<span class="c1"># Sample from the posterior</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">+</span> <span class="n">num_warmup</span><span class="p">)):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">sgld</span><span class="p">)(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="n">num_warmup</span><span class="p">:</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='3340' class='' max='3340' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [3340/3340 00:39&lt;00:00]
    </div>
    </div></div>
</div>
<p>Let us plot the accuracy at different points in the sampling process:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of sampling steps&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction accuracy&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_warmup</span> <span class="o">+</span> <span class="n">num_samples</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sample from 3-layer MLP posterior (MNIST dataset) with SgLD&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/ab83bcf59834b24d4dea330799c19ea85e88eb0b802c41f46aa4cf4d09cae5ac.png" src="../_images/ab83bcf59834b24d4dea330799c19ea85e88eb0b802c41f46aa4cf4d09cae5ac.png" />
</div>
</div>
<section id="sampling-with-sghmc">
<h3>Sampling with SGHMC<a class="headerlink" href="#sampling-with-sghmc" title="Permalink to this headline">#</a></h3>
<p>We can also use SGHMC to samples from this model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the SGHMC kernel with a constant learning rate</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">9e-6</span>
<span class="n">grad_fn</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="n">logprior_fn</span><span class="p">,</span> <span class="n">loglikelihood_fn</span><span class="p">,</span> <span class="n">data_size</span><span class="p">)</span>
<span class="n">sghmc</span> <span class="o">=</span> <span class="n">blackjax</span><span class="o">.</span><span class="n">sghmc</span><span class="p">(</span><span class="n">grad_fn</span><span class="p">)</span>

<span class="c1"># Batch the data</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">init</span><span class="p">)(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Sample from the posterior</span>
<span class="n">sghmc_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">+</span> <span class="n">num_warmup</span><span class="p">)):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
    <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">sghmc</span><span class="p">)(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">sghmc_accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">sghmc_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sghmc_accuracy</span><span class="p">)</span>
        <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="n">num_warmup</span><span class="p">:</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='3323' class='' max='3340' style='width:300px; height:20px; vertical-align: middle;'></progress>
      99.49% [3323/3340 03:19&lt;00:01]
    </div>
    </div><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">15</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span> <span class="o">+</span> <span class="n">num_warmup</span><span class="p">)):</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>     <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">15</span>     <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>     <span class="n">state</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">sghmc</span><span class="p">)(</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">minibatch</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

<span class="nn">Cell In[3], line 25,</span> in <span class="ni">batch_data</span><span class="nt">(rng_key, data, batch_size, data_size)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>     <span class="n">key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">data_size</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">25</span> <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">elem</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="k">yield</span> <span class="n">minibatch</span>

<span class="nn">Cell In[3], line 25,</span> in <span class="ni">&lt;genexpr&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span> <span class="n">_</span><span class="p">,</span> <span class="n">rng_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>     <span class="n">key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">data_size</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">25</span> <span class="n">minibatch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">elem</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="k">yield</span> <span class="n">minibatch</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/array.py:261,</span> in <span class="ni">ArrayImpl.__getitem__</span><span class="nt">(self, idx)</span>
<span class="g g-Whitespace">    </span><span class="mi">258</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_if_deleted</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">260</span> <span class="k">if</span> <span class="n">dispatch</span><span class="o">.</span><span class="n">is_single_device_sharding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sharding</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_fully_replicated</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">261</span>   <span class="k">return</span> <span class="n">lax_numpy</span><span class="o">.</span><span class="n">_rewriting_take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">262</span> <span class="c1"># TODO(yashkatariya): Make it work for other Shardings too wherever its</span>
<span class="g g-Whitespace">    </span><span class="mi">263</span> <span class="c1"># possible to not do data movement.</span>
<span class="g g-Whitespace">    </span><span class="mi">264</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sharding</span><span class="p">,</span> <span class="n">PmapSharding</span><span class="p">):</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3828,</span> in <span class="ni">_rewriting_take</span><span class="nt">(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)</span>
<span class="g g-Whitespace">   </span><span class="mi">3825</span>       <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">dynamic_index_in_dim</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">3827</span> <span class="n">treedef</span><span class="p">,</span> <span class="n">static_idx</span><span class="p">,</span> <span class="n">dynamic_idx</span> <span class="o">=</span> <span class="n">_split_index_for_jit</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">3828</span> <span class="k">return</span> <span class="n">_gather</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">treedef</span><span class="p">,</span> <span class="n">static_idx</span><span class="p">,</span> <span class="n">dynamic_idx</span><span class="p">,</span> <span class="n">indices_are_sorted</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3829</span>                <span class="n">unique_indices</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3837,</span> in <span class="ni">_gather</span><span class="nt">(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)</span>
<span class="g g-Whitespace">   </span><span class="mi">3834</span> <span class="k">def</span> <span class="nf">_gather</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">treedef</span><span class="p">,</span> <span class="n">static_idx</span><span class="p">,</span> <span class="n">dynamic_idx</span><span class="p">,</span> <span class="n">indices_are_sorted</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">3835</span>             <span class="n">unique_indices</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">3836</span>   <span class="n">idx</span> <span class="o">=</span> <span class="n">_merge_static_and_dynamic_indices</span><span class="p">(</span><span class="n">treedef</span><span class="p">,</span> <span class="n">static_idx</span><span class="p">,</span> <span class="n">dynamic_idx</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">3837</span>   <span class="n">indexer</span> <span class="o">=</span> <span class="n">_index_to_gather</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">arr</span><span class="p">),</span> <span class="n">idx</span><span class="p">)</span>  <span class="c1"># shared with _scatter_update</span>
<span class="g g-Whitespace">   </span><span class="mi">3838</span>   <span class="n">y</span> <span class="o">=</span> <span class="n">arr</span>
<span class="g g-Whitespace">   </span><span class="mi">3840</span>   <span class="k">if</span> <span class="n">fill_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4007,</span> in <span class="ni">_index_to_gather</span><span class="nt">(x_shape, idx, normalize_indices)</span>
<span class="g g-Whitespace">   </span><span class="mi">4000</span> <span class="k">for</span> <span class="n">idx_pos</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">4001</span>   <span class="c1"># Handle the advanced indices here if:</span>
<span class="g g-Whitespace">   </span><span class="mi">4002</span>   <span class="c1"># * the advanced indices were not contiguous and we are the start.</span>
<span class="g g-Whitespace">   </span><span class="mi">4003</span>   <span class="c1"># * we are at the position of the first advanced index.</span>
<span class="g g-Whitespace">   </span><span class="mi">4004</span>   <span class="k">if</span> <span class="p">(</span><span class="n">advanced_indexes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
<span class="g g-Whitespace">   </span><span class="mi">4005</span>       <span class="p">(</span><span class="n">advanced_axes_are_contiguous</span> <span class="ow">and</span> <span class="n">idx_pos</span> <span class="o">==</span> <span class="n">idx_advanced_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">or</span>
<span class="g g-Whitespace">   </span><span class="mi">4006</span>        <span class="ow">not</span> <span class="n">advanced_axes_are_contiguous</span> <span class="ow">and</span> <span class="n">idx_pos</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)):</span>
<span class="ne">-&gt; </span><span class="mi">4007</span>     <span class="n">advanced_indexes</span> <span class="o">=</span> <span class="n">broadcast_arrays</span><span class="p">(</span><span class="o">*</span><span class="n">advanced_indexes</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">4008</span>     <span class="n">shape</span> <span class="o">=</span> <span class="n">advanced_indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="g g-Whitespace">   </span><span class="mi">4009</span>     <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:1159,</span> in <span class="ni">broadcast_arrays</span><span class="nt">(*args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1155</span> <span class="nd">@_wraps</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">broadcast_arrays</span><span class="p">,</span> <span class="n">lax_description</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span><span class="se">\</span>
<span class="g g-Whitespace">   </span><span class="mi">1156</span><span class="s2"> The JAX version does not necessarily return a view of the input.</span>
<span class="g g-Whitespace">   </span><span class="mi">1157</span><span class="s2"> &quot;&quot;&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1158</span> <span class="k">def</span> <span class="nf">broadcast_arrays</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Array</span><span class="p">]:</span>
<span class="ne">-&gt; </span><span class="mi">1159</span>   <span class="k">return</span> <span class="n">_broadcast_arrays</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">1</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/_src/api.py:612,</span> in <span class="ni">_cpp_jit.&lt;locals&gt;.cache_miss</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">608</span>   <span class="n">flat_fun</span> <span class="o">=</span> <span class="n">lu</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">flat_fun</span><span class="p">,</span> <span class="n">in_type</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">610</span> <span class="n">primitive</span> <span class="o">=</span> <span class="n">xla</span><span class="o">.</span><span class="n">xla_call_p</span>
<span class="g g-Whitespace">    </span><span class="mi">611</span> <span class="n">call_bind_continuation</span><span class="p">,</span> <span class="n">top_trace</span><span class="p">,</span> <span class="n">fun_</span><span class="p">,</span> <span class="n">tracers</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">612</span>     <span class="n">core</span><span class="o">.</span><span class="n">call_bind_with_continuation</span><span class="p">(</span><span class="n">primitive</span><span class="p">,</span> <span class="n">flat_fun</span><span class="p">,</span> <span class="o">*</span><span class="n">args_flat</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">613</span>     <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">614</span>     <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">615</span>     <span class="n">name</span><span class="o">=</span><span class="n">flat_fun</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">616</span>     <span class="n">donated_invars</span><span class="o">=</span><span class="n">donated_invars</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">617</span>     <span class="n">inline</span><span class="o">=</span><span class="n">inline</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">618</span>     <span class="n">keep_unused</span><span class="o">=</span><span class="n">keep_unused</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">619</span> <span class="n">execute</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">620</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">top_trace</span><span class="p">,</span> <span class="n">core</span><span class="o">.</span><span class="n">EvalTrace</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">621</span>     <span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">jax_debug_nans</span> <span class="ow">or</span> <span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">jax_debug_infs</span><span class="p">):</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/core.py:2036,</span> in <span class="ni">call_bind_with_continuation</span><span class="nt">(primitive, fun, *args, **params)</span>
<span class="g g-Whitespace">   </span><span class="mi">2035</span> <span class="k">def</span> <span class="nf">call_bind_with_continuation</span><span class="p">(</span><span class="n">primitive</span><span class="p">:</span> <span class="n">CallPrimitive</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">2036</span>   <span class="n">top_trace</span> <span class="o">=</span> <span class="n">find_top_trace</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2037</span>   <span class="n">fun_</span><span class="p">,</span> <span class="n">env_trace_todo</span> <span class="o">=</span> <span class="n">process_env_traces_call</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">2038</span>       <span class="n">fun</span><span class="p">,</span> <span class="n">primitive</span><span class="p">,</span> <span class="n">top_trace</span> <span class="ow">and</span> <span class="n">top_trace</span><span class="o">.</span><span class="n">level</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
<span class="g g-Whitespace">   </span><span class="mi">2039</span>   <span class="n">tracers</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">top_trace</span><span class="o">.</span><span class="n">full_raise</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/jax/core.py:1123,</span> in <span class="ni">find_top_trace</span><span class="nt">(xs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1121</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1122</span>   <span class="n">top_main</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
<span class="ne">-&gt; </span><span class="mi">1123</span> <span class="n">dynamic</span> <span class="o">=</span> <span class="n">thread_local_state</span><span class="o">.</span><span class="n">trace_state</span><span class="o">.</span><span class="n">trace_stack</span><span class="o">.</span><span class="n">dynamic</span>
<span class="g g-Whitespace">   </span><span class="mi">1124</span> <span class="n">top_main</span> <span class="o">=</span> <span class="p">(</span><span class="n">dynamic</span> <span class="k">if</span> <span class="n">top_main</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">level</span> <span class="o">&gt;</span> <span class="n">top_main</span><span class="o">.</span><span class="n">level</span>
<span class="g g-Whitespace">   </span><span class="mi">1125</span>             <span class="k">else</span> <span class="n">top_main</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="k">return</span> <span class="n">top_main</span> <span class="ow">and</span> <span class="n">top_main</span><span class="o">.</span><span class="n">with_cur_sublevel</span><span class="p">()</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ld_plot</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
<span class="n">hmc_plot</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">sghmc_accuracies</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of sampling steps&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction accuracy&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_warmup</span> <span class="o">+</span> <span class="n">num_samples</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sample from 3-layer MLP posterior (MNIST dataset)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="n">ld_plot</span><span class="p">,</span> <span class="n">hmc_plot</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;SGLD&#39;</span><span class="p">,</span> <span class="s1">&#39;SGHMC&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The average accuracy for SGLD in the sampling phase is </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accuracies</span><span class="p">[</span><span class="mi">10</span><span class="p">:])</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The average accuracy for SGHMC in the sampling phase is </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sghmc_accuracies</span><span class="p">[</span><span class="mi">10</span><span class="p">:])</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>Which is not a bad accuracy at all for such a simple model! Remember though that we draw samples from the posterior distribution of the digit probabilities; we can thus use this information to filter out examples for which the model is “unsure” of its prediction.</p>
<p>Here we will say that the model is unsure of its prediction for a given image if the digit that is most often predicted for this image is predicted less tham 95% of the time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_class</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">s</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_test_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">max_predicted</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test_samples</span><span class="p">)]</span>
<span class="n">freq_max_predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="n">max_predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">max_predicted</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">num_samples</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test_samples</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">certain_mask</span> <span class="o">=</span> <span class="n">freq_max_predicted</span> <span class="o">&gt;</span> <span class="mf">0.95</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s plot a few examples where the model was very uncertain:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">most_uncertain_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">freq_max_predicted</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">max_predicted</span><span class="p">[</span><span class="n">most_uncertain_idx</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span> <span class="o">/</span> <span class="mi">2000</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">most_uncertain_idx</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And now compute the average accuracy over all the samples without these uncertain predictions:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">avg_accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
    <span class="p">[</span><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">X_test</span><span class="p">[</span><span class="n">certain_mask</span><span class="p">],</span> <span class="n">y_test</span><span class="p">[</span><span class="n">certain_mask</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;The average accuracy removing the samples for which the model is uncertain is </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">avg_accuracy</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="GP_Marginal.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Bayesian Regression With Latent Gaussian Sampler</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="change_of_variable_hmc.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Change of Variable in HMC</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Blackjax developers<br/>
  
      &copy; Copyright 2022, The Blackjax developers.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>