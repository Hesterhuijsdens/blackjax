
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Pathfinder &#8212; Blackjax</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Regime switching Hidden Markov model" href="RegimeSwitchingModel.html" />
    <link rel="prev" title="Change of Variable in HMC" href="change_of_variable_hmc.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/blackjax.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Blackjax</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  HOW TO
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../howto_use_ppl.html">
   Use the model I built with X?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_aesara.html">
     Use with Aesara models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_numpyro.html">
     Use with Numpyro models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_oryx.html">
     Use with Oryx models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="howto_use_tfp.html">
     Use with TFP models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_sample_multiple_chains.html">
   Sample with multiple chains?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_custom_gradients.html">
   Use custom gradients?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="howto_other_frameworks.html">
   Use non-JAX log-prob functions?
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Blackjax by example
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../examples.html">
   Examples
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Introduction.html">
     A Quick Introduction to Blackjax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegression.html">
     Bayesian Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="LogisticRegressionWithLatentGaussianSampler.html">
     Bayesian Logistic Regression With Latent Gaussian Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="TemperedSMC.html">
     Use Tempered SMC to Improve Exploration of MCMC Methods.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalBNN.html">
     Hierarchical Bayesian Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="PeriodicOrbitalMCMC.html">
     Periodic Orbital MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GP_EllipticalSliceSampler.html">
     Gaussian Regression with the Elliptical Slice Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="GP_Marginal.html">
     Bayesian Regression With Latent Gaussian Sampler
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SGMCMC.html">
     MNIST Digit Recognition With a 3-Layer Perceptron
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="change_of_variable_hmc.html">
     Change of Variable in HMC
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Pathfinder
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="RegimeSwitchingModel.html">
     Regime switching Hidden Markov model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="SparseLogisticRegression.html">
     Sparse logistic regression
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mcmc.html">
   MCMC sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sgmcmc.html">
   Stochastic gradient MCMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../smc.html">
   Sequential Monte Carlo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vi.html">
   Variational Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../adaptation.html">
   Adaptation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../diagnostics.html">
   Diagnostics
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/blackjax-devs/blackjax"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data">
   The Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-model">
   The Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pathfinder-parallel-quasi-newton-variational-inference">
   Pathfinder: Parallel Quasi-Newton Variational Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pathfinder-as-a-variational-inference-method">
   Pathfinder as a Variational Inference Method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pathfinder-as-an-initialization-tool-for-mcmc-kernels">
     Pathfinder as an Initialization Tool for MCMC Kernels
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-caveats">
   Some Caveats
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Pathfinder</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data">
   The Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-model">
   The Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pathfinder-parallel-quasi-newton-variational-inference">
   Pathfinder: Parallel Quasi-Newton Variational Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pathfinder-as-a-variational-inference-method">
   Pathfinder as a Variational Inference Method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pathfinder-as-an-initialization-tool-for-mcmc-kernels">
     Pathfinder as an Initialization Tool for MCMC Kernels
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-caveats">
   Some Caveats
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="pathfinder">
<h1>Pathfinder<a class="headerlink" href="#pathfinder" title="Permalink to this headline">#</a></h1>
<p>In this notebook we introduce the pathfinder algorithm and we show how to use it as a variational inference method or as an initialization tool for MCMC kernels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import jax
import jax.numpy as jnp
import jax.random as random
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from sklearn.datasets import make_biclusters

import blackjax
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.rcParams[&quot;axes.spines.right&quot;] = False
plt.rcParams[&quot;axes.spines.top&quot;] = False
plt.rcParams[&quot;figure.figsize&quot;] = (10, 6)
</pre></div>
</div>
</div>
</details>
</div>
<section id="the-data">
<h2>The Data<a class="headerlink" href="#the-data" title="Permalink to this headline">#</a></h2>
<p>We create two clusters of points using <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html?highlight=bicluster%20data#sklearn.datasets.make_biclusters">scikit-learn’s <code class="docutils literal notranslate"><span class="pre">make_bicluster</span></code> function</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>num_points = 50
X, rows, cols = make_biclusters(
    (num_points, 2), 2, noise=0.6, random_state=314, minval=-3, maxval=3
)
y = rows[0] * 1.0  # y[i] = whether point i belongs to cluster 1
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>colors = [&quot;tab:red&quot; if el else &quot;tab:blue&quot; for el in rows[0]]
plt.scatter(*X.T, edgecolors=colors, c=&quot;none&quot;)
plt.xlabel(r&quot;$X_0$&quot;)
plt.ylabel(r&quot;$X_1$&quot;)
plt.show()
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/b1b7e9ad57ff2356b0f7ebcfcb367ec0c65f66de508fa469b3a00f26402a68ec.png" src="../_images/b1b7e9ad57ff2356b0f7ebcfcb367ec0c65f66de508fa469b3a00f26402a68ec.png" />
</div>
</div>
</section>
<section id="the-model">
<h2>The Model<a class="headerlink" href="#the-model" title="Permalink to this headline">#</a></h2>
<p>We use a simple logistic regression model to infer to which cluster each of the points belongs. We note $ y $ a binary variable that indicates whether a point belongs to the first cluster:</p>
<p>$$
y \sim \operatorname{Bernoulli}(p)
$$</p>
<p>The probability <span class="math notranslate nohighlight">\(p\)</span> to belong to the first cluster commes from a logistic regression:</p>
<p>$$
p = \operatorname{logistic}(\Phi,\boldsymbol{w})
$$</p>
<p>where <span class="math notranslate nohighlight">\(w\)</span> is a vector of weights whose priors are a normal prior centered on 0:</p>
<p>$$
\boldsymbol{w} \sim \operatorname{Normal}(0, \sigma)
$$</p>
<p>And <span class="math notranslate nohighlight">\(\Phi\)</span> is the matrix that contains the data, so each row <span class="math notranslate nohighlight">\(\Phi_{i,:}\)</span> is the vector <span class="math notranslate nohighlight">\(\left[X_0^i, X_1^i\right]\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Phi = X
N, M = Phi.shape


def sigmoid(z):
    return jnp.exp(z) / (1 + jnp.exp(z))


def log_sigmoid(z):
    return z - jnp.log(1 + jnp.exp(z))


def logprob_fn(w, alpha=1.0):
    &quot;&quot;&quot;The log-probability density function of the posterior distribution of the model.&quot;&quot;&quot;
    log_an = log_sigmoid(Phi @ w)
    an = Phi @ w
    log_likelihood_term = y * log_an + (1 - y) * jnp.log(1 - sigmoid(an))
    prior_term = alpha * w @ w / 2

    return -prior_term + log_likelihood_term.sum()
</pre></div>
</div>
</div>
</div>
</section>
<section id="pathfinder-parallel-quasi-newton-variational-inference">
<h2>Pathfinder: Parallel Quasi-Newton Variational Inference<a class="headerlink" href="#pathfinder-parallel-quasi-newton-variational-inference" title="Permalink to this headline">#</a></h2>
<p>Starting from a random initialization, Pathfinder locates normal approximations to the target
density along a quasi-Newton optimization path, with local covariance estimated using the inverse Hessian
estimates produced by the optimizer. Pathfinder returns draws from the approximation with the lowest
estimated Kullback-Leibler (KL) divergence to the true posterior.
The optimizer is the limited memory BFGS algorithm.</p>
<p>To help understand the approximations that pathfinder evaluates during its run, here we plot for each step of the L-BFGS optimizer the approximation of the posterior distribution of the model derived by pathfinder and its ELBO:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rng_key = random.PRNGKey(314)
w0 = random.multivariate_normal(rng_key, 2.0 + jnp.zeros(M), jnp.eye(M))
_, info = blackjax.vi.pathfinder.approximate(rng_key, logprob_fn, w0, ftol=1e-4)
path = info.path
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def ellipse_confidence(mu, cov, ax, c, n_std=2.0):
    import numpy as np

    lambda_, v = np.linalg.eig(cov)
    lambda_ = np.sqrt(lambda_)
    ellipse = Ellipse(
        xy=(*mu,),
        width=lambda_[0] * n_std * 2,
        height=lambda_[1] * n_std * 2,
        angle=np.degrees(np.arctan2(*v[:, 0][::-1])),
        facecolor=c,
        edgecolor=&quot;b&quot;,
        alpha=0.1,
    )
    return ax.add_artist(ellipse)


step = 0.1
x_, y_ = jnp.mgrid[-1:3:step, -1:3:step]
pos_ = jnp.dstack((x_, y_))
logp_ = jnp.nan_to_num(
    jax.vmap(logprob_fn)(pos_.reshape(-1, M)).reshape(pos_.shape[0], pos_.shape[1]),
    nan=-1e10,
)
levels_ = jnp.percentile(logp_.flatten(), jnp.linspace(60, 100, 10))


steps = (jnp.isfinite(path.elbo)).sum()
rows = int(jnp.ceil(steps / 3))
fig, axs = plt.subplots(rows, 3, figsize=(15, 5 * rows), sharex=True, sharey=True)

for i, ax in zip(range(1, steps + 1), axs.flatten()):

    ax.contour(x_, y_, logp_, levels=levels_)
    state = jax.tree_map(lambda x: x[i], path)
    sample_state, _ = blackjax.vi.pathfinder.sample(rng_key, state, 10_000)
    position_path = path.position[: i + 1]
    ax.plot(
        position_path[:, 0],
        position_path[:, 1],
        marker=&quot;*&quot;,
        linestyle=&quot;--&quot;,
        markersize=10,
    )
    mu_i, cov_i = sample_state.mean(0), jnp.cov(sample_state, rowvar=False)
    ellipse_confidence(mu_i, cov_i, ax, &quot;r&quot;)
    ax.set_title(f&quot;Iteration: {i+1}\nEstimated ELBO: {state.elbo:.2f}&quot;)
fig.show()
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/8f90277a3c4e2c9e0e1ca7d27930ab6e20e532edccfb88d8917e2a6e1b508334.png" src="../_images/8f90277a3c4e2c9e0e1ca7d27930ab6e20e532edccfb88d8917e2a6e1b508334.png" />
</div>
</div>
</section>
<section id="pathfinder-as-a-variational-inference-method">
<h2>Pathfinder as a Variational Inference Method<a class="headerlink" href="#pathfinder-as-a-variational-inference-method" title="Permalink to this headline">#</a></h2>
<p>Pathfinder can be used as a variational inference method, using its kernel API:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>pathfinder = blackjax.kernels.pathfinder(logprob_fn)
state, _ = pathfinder.approximate(rng_key, w0, ftol=1e-4)
</pre></div>
</div>
</div>
</div>
<p>We can now get samples from the approximation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>_, rng_key = random.split(rng_key)
samples, _ = pathfinder.sample(rng_key, state, 5_000)
</pre></div>
</div>
</div>
</div>
<p>And display the trace:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, ax = plt.subplots(1, 2, figsize=(8, 2), sharey=True)
for i, axi in enumerate(ax):
    axi.plot(samples[:, i])
    axi.set_title(f&quot;$w_{i}$&quot;)
plt.show()
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/154021a8e18c6e6c106e0b13add41a15b8edadc035326f8c5a1d95e7ccc085f5.png" src="../_images/154021a8e18c6e6c106e0b13add41a15b8edadc035326f8c5a1d95e7ccc085f5.png" />
</div>
</div>
<p>Please note that pathfinder is implemented as follows:</p>
<ul class="simple">
<li><p>it runs L-BFGS optimization and finds the best approximation in the <code class="docutils literal notranslate"><span class="pre">init</span></code> phase</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step</span></code> phase it’s just sampling from a multinormal distribution, whose parameters have been already estimated</p></li>
</ul>
<p>hence it makes sense to <code class="docutils literal notranslate"><span class="pre">jit</span></code> the <code class="docutils literal notranslate"><span class="pre">init</span></code> function and then use the <code class="docutils literal notranslate"><span class="pre">blackjax.vi.pathfinder.sample_from_state</span></code> helper function instead of implementing the inference loop:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%time

state, _ = jax.jit(pathfinder.approximate)(rng_key, w0)
samples, _ = pathfinder.sample(rng_key, state, 5_000)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 4.04 s, sys: 40.1 ms, total: 4.08 s
Wall time: 4.07 s
</pre></div>
</div>
</div>
</div>
<p>Quick comparison against <code class="docutils literal notranslate"><span class="pre">rmh</span></code> kernel:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def inference_loop(rng_key, kernel, initial_state, num_samples):
    @jax.jit
    def one_step(state, rng_key):
        state, info = kernel(rng_key, state)
        return state, (state, info)

    keys = jax.random.split(rng_key, num_samples)
    return jax.lax.scan(one_step, initial_state, keys)

rmh = blackjax.kernels.rmh(logprob_fn, sigma=jnp.ones(M) * 0.7)
state_rmh = rmh.init(w0)
_, (samples_rmh, _) = inference_loop(rng_key, rmh.step, state_rmh, 5_000)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, ax = plt.subplots(2, 2, figsize=(10, 4), sharey=True)
for i in range(2):
    ax[i, 0].plot(samples_rmh.position[:, i])
    ax[i, 0].axvline(x=300, c=&quot;tab:red&quot;)
    ax[i, 0].set_ylabel(f&quot;$w_{i}$&quot;)
    ax[i, 1].plot(samples[:, i])

ax[0, 0].set_title(&quot;RMH&quot;)
ax[0, 1].set_title(&quot;Pathfinder&quot;)
fig.show()
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/ee7bba82ae3c4b1ff9724d62edfcc5c7ef0798d343b2a84b3b8e67db85354e14.png" src="../_images/ee7bba82ae3c4b1ff9724d62edfcc5c7ef0798d343b2a84b3b8e67db85354e14.png" />
</div>
</div>
<section id="pathfinder-as-an-initialization-tool-for-mcmc-kernels">
<h3>Pathfinder as an Initialization Tool for MCMC Kernels<a class="headerlink" href="#pathfinder-as-an-initialization-tool-for-mcmc-kernels" title="Permalink to this headline">#</a></h3>
<p>Pathfinder uses internally the inverse hessian estimation of the L-BFGS optimizer to evaluate the approximations to the target distribution along the quasi-Newton optimization path.</p>
<p>We can calculate explicitly this inverse hessian matrix for a step of the optimization path using the <code class="docutils literal notranslate"><span class="pre">blackjax.vi.pathfinder.lbfgs_inverse_hessian_formula_1</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from blackjax.optimizers.lbfgs import lbfgs_inverse_hessian_formula_1

inverse_mass_matrix = lbfgs_inverse_hessian_formula_1(
    state.alpha, state.beta, state.gamma
)
inverse_mass_matrix
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[ 0.22071719, -0.05641349],
       [-0.05641348,  0.23935075]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>This estimation of the inverse mass matrix, coupled with Nesterov’s dual averaging adaptation for estimating the step size, yields an alternative adaptation scheme for initializing MCMC kernels.</p>
<p>This scheme is implemented in <code class="docutils literal notranslate"><span class="pre">blackjax.kernel.pathfinder_adaptation</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>adapt = blackjax.kernels.pathfinder_adaptation(blackjax.nuts, logprob_fn)
state, kernel, info = adapt.run(rng_key, w0, 400)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="some-caveats">
<h2>Some Caveats<a class="headerlink" href="#some-caveats" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>L-BFGS algorithm struggles with float32s and log-likelihood functions; it’s suggested to use double precision numbers. In order to do that in <code class="docutils literal notranslate"><span class="pre">jax</span></code> a configuration variable needs to be set up at initialization time (see <a class="reference external" href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision">here</a>)</p></li>
<li><p>otherwise you can stick with float32 mode and try to tweak <code class="docutils literal notranslate"><span class="pre">ftol</span></code>, <code class="docutils literal notranslate"><span class="pre">gtol</span></code>, or the initialization point</p></li>
<li><p>It may make sense to start pathfinder with a “bad” initialization point, in order to make the L-BFGS algorithm run longer and have more datapoints to estimate the inverse hessian matrix.</p></li>
</ul>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="change_of_variable_hmc.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Change of Variable in HMC</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="RegimeSwitchingModel.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Regime switching Hidden Markov model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Blackjax developers<br/>
  
      &copy; Copyright 2022, The Blackjax developers.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>